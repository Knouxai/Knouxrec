import { enhancedModelManager } from "./enhancedModelManager";
import { feedbackService } from "./feedbackService";

export interface OfflineAITool {
  id: string;
  name: string;
  nameEn: string;
  description: string;
  category: "text" | "video" | "image" | "audio" | "analysis";
  icon: string;
  offline: true;
  modelPath: string;
  modelSize: number; // MB
  inputTypes: string[];
  outputTypes: string[];
  processingTime: number; // seconds estimate
  difficulty: "easy" | "medium" | "hard";
  credits: number;
  features: string[];
  lastUsed?: Date;
  timesUsed: number;
}

export interface ToolExecutionResult {
  success: boolean;
  outputPath?: string;
  outputData?: any;
  error?: string;
  processingTime: number;
  metadata?: Record<string, any>;
}

export interface ToolExecutionOptions {
  inputFile?: File;
  inputText?: string;
  settings?: Record<string, any>;
  outputFormat?: string;
  quality?: "fast" | "balanced" | "high";
}

export class OfflineAIToolsService {
  private tools: Map<string, OfflineAITool> = new Map();
  private executionHistory: Map<string, ToolExecutionResult[]> = new Map();
  private processingCallbacks = new Map<
    string,
    (progress: number, stage: string) => void
  >();

  constructor() {
    this.initializeTools();
  }

  private initializeTools(): void {
    const toolsData: OfflineAITool[] = [
      // ğŸ–¼ï¸ Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØµÙˆØ± (Image Tools) - 10 Ø£Ø¯ÙˆØ§Øª
      {
        id: "remove_background",
        name: "Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©",
        nameEn: "Remove Background",
        description: "Ø¥Ø²Ø§Ù„Ø© Ø®Ù„ÙÙŠØ© Ø§Ù„ØµÙˆØ± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… U-2-Net Ø§Ù„Ù…Ø­Ù„ÙŠ",
        category: "image",
        icon: "ğŸ–¼ï¸",
        offline: true,
        modelPath: "/models/u2net/model.json",
        modelSize: 95,
        inputTypes: ["image/jpeg", "image/png", "image/webp"],
        outputTypes: ["image/png"],
        processingTime: 3,
        difficulty: "easy",
        credits: 2,
        features: ["Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©", "Ø­ÙˆØ§Ù Ù†Ø§Ø¹Ù…Ø©", "Ù…Ø¹Ø§Ù„Ø¬Ø© Ø³Ø±ÙŠØ¹Ø©"],
        timesUsed: 0,
      },
      {
        id: "upscale_image",
        name: "ØªÙƒØ¨ÙŠØ± Ø§Ù„ØµÙˆØ±",
        nameEn: "Image Upscaler",
        description: "ØªÙƒØ¨ÙŠØ± Ø§Ù„ØµÙˆØ± ÙˆØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯ØªÙ‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Real-ESRGAN",
        category: "image",
        icon: "ğŸ“ˆ",
        offline: true,
        modelPath: "/models/real_esrgan/model.json",
        modelSize: 150,
        inputTypes: ["image/jpeg", "image/png", "image/webp"],
        outputTypes: ["image/png"],
        processingTime: 8,
        difficulty: "medium",
        credits: 5,
        features: ["ØªÙƒØ¨ÙŠØ± 4x", "ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¬ÙˆØ¯Ø©", "Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ§ØµÙŠÙ„"],
        timesUsed: 0,
      },
      {
        id: "enhance_image",
        name: "ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±",
        nameEn: "Photo Enhancer",
        description: "ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ± ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ ÙˆØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù†",
        category: "image",
        icon: "âœ¨",
        offline: true,
        modelPath: "/models/real_esrgan/model.json",
        modelSize: 150,
        inputTypes: ["image/jpeg", "image/png", "image/webp"],
        outputTypes: ["image/png", "image/jpeg"],
        processingTime: 5,
        difficulty: "easy",
        credits: 3,
        features: ["ØªÙ†Ø¹ÙŠÙ… Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡", "ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ù„ÙˆØ§Ù†", "Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø­Ø¯Ø©"],
        timesUsed: 0,
      },
      {
        id: "detect_objects",
        name: "ÙƒØ´Ù Ø§Ù„Ø£Ø¬Ø³Ø§Ù…",
        nameEn: "Object Detection",
        description: "ÙƒØ´Ù ÙˆØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£Ø¬Ø³Ø§Ù… ÙÙŠ Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… YOLOv8",
        category: "image",
        icon: "ğŸ¯",
        offline: true,
        modelPath: "/models/yolo/model.json",
        modelSize: 45,
        inputTypes: ["image/jpeg", "image/png", "image/webp"],
        outputTypes: ["application/json", "image/png"],
        processingTime: 2,
        difficulty: "easy",
        credits: 2,
        features: ["80+ ÙØ¦Ø©", "Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©", "Ù…Ø¹Ø§ÙŠØ±Ø© Ø³Ø±ÙŠØ¹Ø©"],
        timesUsed: 0,
      },
      {
        id: "detect_faces",
        name: "ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡",
        nameEn: "Face Detection",
        description: "Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡ ÙˆÙ†Ù‚Ø§Ø· Ø§Ù„ÙˆØ¬Ù‡ ÙÙŠ Ø§Ù„ØµÙˆØ±",
        category: "image",
        icon: "ğŸ‘¤",
        offline: true,
        modelPath: "/models/face_detection/model.json",
        modelSize: 10,
        inputTypes: ["image/jpeg", "image/png", "image/webp"],
        outputTypes: ["application/json", "image/png"],
        processingTime: 1,
        difficulty: "easy",
        credits: 1,
        features: ["Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©", "Ù†Ù‚Ø§Ø· Ø§Ù„ÙˆØ¬Ù‡", "Ù…Ø¹Ø§Ù„Ø¬Ø© Ø³Ø±ÙŠØ¹Ø©"],
        timesUsed: 0,
      },
      {
        id: "face_swap",
        name: "ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„ÙˆØ¬ÙˆÙ‡",
        nameEn: "Face Swap",
        description: "ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„ÙˆØ¬ÙˆÙ‡ Ø¨ÙŠÙ† Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… SimSwap",
        category: "image",
        icon: "ğŸ”„",
        offline: true,
        modelPath: "/models/simswap/model.json",
        modelSize: 320,
        inputTypes: ["image/jpeg", "image/png"],
        outputTypes: ["image/png"],
        processingTime: 15,
        difficulty: "hard",
        credits: 10,
        features: ["Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ù‚Ø¹ÙŠØ©", "Ø­ÙØ¸ Ø§Ù„Ù‡ÙˆÙŠØ©", "Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¯Ù‚ÙŠÙ‚Ø©"],
        timesUsed: 0,
      },
      {
        id: "colorize_image",
        name: "ØªÙ„ÙˆÙŠÙ† Ø§Ù„ØµÙˆØ± Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©",
        nameEn: "Colorize Old Photos",
        description: "ØªÙ„ÙˆÙŠÙ† Ø§Ù„ØµÙˆØ± Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙˆØ§Ù„Ø£Ø¨ÙŠØ¶ ÙˆØ§Ù„Ø£Ø³ÙˆØ¯ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹",
        category: "image",
        icon: "ğŸ¨",
        offline: true,
        modelPath: "/models/stable_diffusion/model.json",
        modelSize: 2560,
        inputTypes: ["image/jpeg", "image/png", "image/webp"],
        outputTypes: ["image/png"],
        processingTime: 20,
        difficulty: "hard",
        credits: 15,
        features: ["Ø£Ù„ÙˆØ§Ù† Ø·Ø¨ÙŠØ¹ÙŠØ©", "Ø­ÙØ¸ Ø§Ù„ØªÙØ§ØµÙŠÙ„", "Ù†ØªØ§Ø¦Ø¬ ØªØ§Ø±ÙŠØ®ÙŠØ©"],
        timesUsed: 0,
      },
      {
        id: "toonify_image",
        name: "ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ø³Ù…Ø©",
        nameEn: "Toonify Image",
        description: "ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø§ï¿½ï¿½Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¥Ù„Ù‰ Ø±Ø³ÙˆÙ… Ù…ØªØ­Ø±ÙƒØ©",
        category: "image",
        icon: "ğŸ­",
        offline: true,
        modelPath: "/models/stable_diffusion/model.json",
        modelSize: 2560,
        inputTypes: ["image/jpeg", "image/png", "image/webp"],
        outputTypes: ["image/png"],
        processingTime: 18,
        difficulty: "hard",
        credits: 12,
        features: ["Ø£Ø³Ù„ÙˆØ¨ ÙƒØ±ØªÙˆÙ†ÙŠ", "Ø£Ù„ÙˆØ§Ù† Ø²Ø§Ù‡ÙŠØ©", "Ø®Ø·ÙˆØ· ÙˆØ§Ø¶Ø­Ø©"],
        timesUsed: 0,
      },
      {
        id: "enhance_face",
        name: "ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØ¬Ù‡ ÙˆØ§Ù„Ø¬Ù„Ø¯",
        nameEn: "Face Enhancement",
        description: "ØªØ­Ø³ÙŠÙ† Ù…Ù„Ø§Ù…Ø­ Ø§Ù„ÙˆØ¬Ù‡ ÙˆØ§Ù„Ø¬Ù„Ø¯ ÙÙŠ Ø§Ù„ØµÙˆØ±",
        category: "image",
        icon: "ğŸ’„",
        offline: true,
        modelPath: "/models/real_esrgan/model.json",
        modelSize: 150,
        inputTypes: ["image/jpeg", "image/png", "image/webp"],
        outputTypes: ["image/png"],
        processingTime: 8,
        difficulty: "medium",
        credits: 6,
        features: ["ØªÙ†Ø¹ÙŠÙ… Ø§Ù„Ø¨Ø´Ø±Ø©", "ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¹ÙŠÙ†ÙŠÙ†", "Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¹ÙŠÙˆØ¨"],
        timesUsed: 0,
      },
      {
        id: "edge_detection",
        name: "ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù ÙˆØ§Ù„ØªÙØ§ØµÙŠÙ„",
        nameEn: "Edge Detection",
        description: "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­ÙˆØ§Ù ÙˆØ§Ù„ØªÙØ§ØµÙŠÙ„ Ù…Ù† Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Canny",
        category: "image",
        icon: "ğŸ“",
        offline: true,
        modelPath: "/models/yolo/model.json",
        modelSize: 45,
        inputTypes: ["image/jpeg", "image/png", "image/webp"],
        outputTypes: ["image/png"],
        processingTime: 2,
        difficulty: "easy",
        credits: 1,
        features: ["Ø­ÙˆØ§Ù Ø¯Ù‚ÙŠÙ‚Ø©", "ØªÙØ§ØµÙŠÙ„ ÙˆØ§Ø¶Ø­Ø©", "Ù…Ø¹Ø§Ù„Ø¬Ø© Ø³Ø±ÙŠØ¹Ø©"],
        timesUsed: 0,
      },

      // ğŸï¸ Ø£Ø¯ÙˆØ§ï¿½ï¿½ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ (Video Tools) - 10 Ø£Ø¯ÙˆØ§Øª
      {
        id: "track_objects",
        name: "ØªØªØ¨Ø¹ Ø§Ù„Ø£Ø¬Ø³Ø§Ù…",
        nameEn: "Object Tracking",
        description: "ØªØªØ¨Ø¹ Ø§Ù„Ø£Ø¬Ø³Ø§Ù… ÙÙŠ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… YOLO Tracker",
        category: "video",
        icon: "ğŸ¯",
        offline: true,
        modelPath: "/models/yolo/model.json",
        modelSize: 45,
        inputTypes: ["video/mp4", "video/webm", "video/avi"],
        outputTypes: ["video/mp4", "application/json"],
        processingTime: 30,
        difficulty: "medium",
        credits: 8,
        features: ["ØªØªØ¨Ø¹ Ù…ØªØ¹Ø¯Ø¯", "Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©", "ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"],
        timesUsed: 0,
      },
      {
        id: "extract_scenes",
        name: "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯",
        nameEn: "Scene Extraction",
        description: "ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¥Ù„Ù‰ Ù…Ø´Ø§Ù‡Ø¯ ÙˆØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹",
        category: "video",
        icon: "ğŸ¬",
        offline: true,
        modelPath: "/models/scenecut/model.json",
        modelSize: 50,
        inputTypes: ["video/mp4", "video/webm", "video/avi"],
        outputTypes: ["video/mp4", "application/json"],
        processingTime: 20,
        difficulty: "easy",
        credits: 5,
        features: ["ÙƒØ´Ù ØªÙ„Ù‚Ø§Ø¦ÙŠ", "ØªÙˆÙ‚ÙŠØªØ§Øª Ø¯Ù‚ÙŠÙ‚Ø©", "Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯"],
        timesUsed: 0,
      },
      {
        id: "stabilize_video",
        name: "ØªØ«Ø¨ÙŠØª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ",
        nameEn: "Video Stabilization",
        description: "ØªØ«Ø¨ÙŠØª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ù‡ØªØ² ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±",
        category: "video",
        icon: "ğŸ“¹",
        offline: true,
        modelPath: "/models/yolo/model.json",
        modelSize: 45,
        inputTypes: ["video/mp4", "video/webm", "video/avi"],
        outputTypes: ["video/mp4"],
        processingTime: 45,
        difficulty: "hard",
        credits: 12,
        features: ["ØªØ«Ø¨ÙŠØª Ø°ÙƒÙŠ", "Ø­ÙØ¸ Ø§Ù„Ø¬ÙˆØ¯Ø©", "Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø©"],
        timesUsed: 0,
      },
      {
        id: "enhance_video",
        name: "ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ",
        nameEn: "Video Enhancement",
        description: "ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙˆÙˆØ¶ÙˆØ­ Ø§Ù„ØµÙˆØ±Ø©",
        category: "video",
        icon: "âœ¨",
        offline: true,
        modelPath: "/models/real_esrgan/model.json",
        modelSize: 150,
        inputTypes: ["video/mp4", "video/webm", "video/avi"],
        outputTypes: ["video/mp4"],
        processingTime: 60,
        difficulty: "hard",
        credits: 20,
        features: ["ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¯Ù‚Ø©", "Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡", "Ø£Ù„ÙˆØ§Ù† Ø£ÙØ¶Ù„"],
        timesUsed: 0,
      },
      {
        id: "detect_motion",
        name: "ÙƒØ´Ù Ø§Ù„Ø­Ø±ÙƒØ©",
        nameEn: "Motion Detection",
        description: "ÙƒØ´Ù ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø±ÙƒØ© ÙÙŠ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ",
        category: "video",
        icon: "ğŸƒ",
        offline: true,
        modelPath: "/models/yolo/model.json",
        modelSize: 45,
        inputTypes: ["video/mp4", "video/webm", "video/avi"],
        outputTypes: ["application/json", "video/mp4"],
        processingTime: 25,
        difficulty: "medium",
        credits: 6,
        features: ["Ø­Ø³Ø§Ø³ÙŠØ© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„", "Ù…Ù†Ø§Ø·Ù‚ Ù…Ø­Ø¯Ø¯Ø©", "ØªÙ‚Ø§Ø±ÙŠØ± Ù…ÙØµÙ„Ø©"],
        timesUsed: 0,
      },
      {
        id: "analyze_fps",
        name: "ØªØ­Ù„ÙŠÙ„ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª",
        nameEn: "FPS Analyzer",
        description: "ØªØ­Ù„ÙŠÙ„ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª ÙˆØ¬ÙˆØ¯Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ",
        category: "video",
        icon: "ğŸ“Š",
        offline: true,
        modelPath: "/models/scenecut/model.json",
        modelSize: 50,
        inputTypes: ["video/mp4", "video/webm", "video/avi"],
        outputTypes: ["application/json"],
        processingTime: 5,
        difficulty: "easy",
        credits: 2,
        features: ["Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ÙØµÙ„Ø©", "Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ©", "Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†"],
        timesUsed: 0,
      },
      {
        id: "extract_audio",
        name: "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª",
        nameEn: "Audio Extraction",
        description: "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØªÙŠ Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ",
        category: "video",
        icon: "ğŸ”Š",
        offline: true,
        modelPath: "/models/whisper/model.json",
        modelSize: 85,
        inputTypes: ["video/mp4", "video/webm", "video/avi"],
        outputTypes: ["audio/wav", "audio/mp3"],
        processingTime: 10,
        difficulty: "easy",
        credits: 3,
        features: ["Ø¬ÙˆØ¯Ø© Ø¹Ø§Ù„ÙŠØ©", "ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©", "Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„ØµÙˆØª"],
        timesUsed: 0,
      },
      {
        id: "video_filters",
        name: "ÙÙ„Ø§ØªØ± Ø§Ù„ÙÙŠØ¯ÙŠÙˆ",
        nameEn: "Video Filters",
        description: "ØªØ·Ø¨ÙŠÙ‚ ÙÙ„Ø§ØªØ± ÙˆØªØ£Ø«ÙŠØ±Ø§Øª Ù…ØªÙ†ÙˆØ¹Ø© Ø¹Ù„Ù‰ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ",
        category: "video",
        icon: "ğŸ¨",
        offline: true,
        modelPath: "/models/stable_diffusion/model.json",
        modelSize: 2560,
        inputTypes: ["video/mp4", "video/webm", "video/avi"],
        outputTypes: ["video/mp4"],
        processingTime: 40,
        difficulty: "medium",
        credits: 10,
        features: ["20+ ÙÙ„ØªØ±", "Ù…Ø¹Ø§ÙŠÙ†Ø© Ù…Ø¨Ø§Ø´Ø±Ø©", "Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©"],
        timesUsed: 0,
      },
      {
        id: "extract_faces_video",
        name: "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙˆØ¬ÙˆÙ‡ Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ",
        nameEn: "Video Face Extraction",
        description: "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙˆØ¬ÙˆÙ‡ Ø§Ù„Ø¸Ø§Ù‡Ø±Ø© ÙÙŠ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ",
        category: "video",
        icon: "ğŸ‘¥",
        offline: true,
        modelPath: "/models/face_detection/model.json",
        modelSize: 10,
        inputTypes: ["video/mp4", "video/webm", "video/avi"],
        outputTypes: ["image/zip", "application/json"],
        processingTime: 35,
        difficulty: "medium",
        credits: 8,
        features: ["Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©", "ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ÙˆØ¬ÙˆÙ‡", "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙˆÙ‚ÙŠØª"],
        timesUsed: 0,
      },
      {
        id: "extract_frames",
        name: "ØªØ­ÙˆÙŠÙ„ ÙÙŠØ¯ÙŠÙˆ Ø¥Ù„Ù‰ ØµÙˆØ±",
        nameEn: "Frame Extraction",
        description: "Ø§Ø³ØªØ®Ø±Ø§Ø¬ ï¿½ï¿½Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙƒØµÙˆØ± Ù…Ù†ÙØµÙ„Ø©",
        category: "video",
        icon: "ğŸ–¼ï¸",
        offline: true,
        modelPath: "/models/scenecut/model.json",
        modelSize: 50,
        inputTypes: ["video/mp4", "video/webm", "video/avi"],
        outputTypes: ["image/zip"],
        processingTime: 15,
        difficulty: "easy",
        credits: 4,
        features: ["Ø¯Ù‚Ø© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„", "ÙØªØ±Ø§Øª Ø²Ù…Ù†ÙŠØ©", "Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª"],
        timesUsed: 0,
      },

      // ğŸ”Š Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØµÙˆØª (Audio Tools) - 10 Ø£Ø¯ÙˆØ§Øª
      {
        id: "separate_audio",
        name: "ÙØµÙ„ Ø§Ù„ØµÙˆØª ÙˆØ§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰",
        nameEn: "Audio Separation",
        description: "ÙØµÙ„ Ø§Ù„Ø£ØµÙˆØ§Øª ÙˆØ§Ù„Ø¢Ù„Ø§Øª Ø§Ù„Ù…ÙˆØ³ÙŠÙ‚ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§ï¿½ï¿½ Spleeter",
        category: "audio",
        icon: "ğŸµ",
        offline: true,
        modelPath: "/models/spleeter/model.json",
        modelSize: 150,
        inputTypes: ["audio/wav", "audio/mp3", "audio/flac"],
        outputTypes: ["audio/wav"],
        processingTime: 30,
        difficulty: "medium",
        credits: 8,
        features: ["ÙØµÙ„ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø¬ÙˆØ¯Ø©", "4 Ù…Ø³Ø§Ø±Ø§Øª", "Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬"],
        timesUsed: 0,
      },
      {
        id: "enhance_voice",
        name: "ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØª Ø§Ù„Ø¨Ø´Ø±ÙŠ",
        nameEn: "Voice Enhancement",
        description: "ØªØ­Ø³ÙŠÙ† ÙˆØ¶ÙˆØ­ Ø§ï¿½ï¿½ØµÙˆØª Ø§Ù„Ø¨Ø´Ø±ÙŠ ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙˆÙŠØ´",
        category: "audio",
        icon: "ğŸ¤",
        offline: true,
        modelPath: "/models/rnnoise/model.json",
        modelSize: 15,
        inputTypes: ["audio/wav", "audio/mp3", "audio/flac"],
        outputTypes: ["audio/wav"],
        processingTime: 15,
        difficulty: "easy",
        credits: 5,
        features: ["Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡", "ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØ¶ÙˆØ­", "Ù…Ø¹Ø§ÙŠØ±Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ©"],
        timesUsed: 0,
      },
      {
        id: "detect_silence",
        name: "ÙƒØ´Ù ÙØªØ±Ø§Øª Ø§Ù„ØµÙ…Øª",
        nameEn: "Silence Detection",
        description: "Ø§ÙƒØªØ´Ø§Ù ÙˆØªØ­Ø¯ÙŠØ¯ ÙØªØ±Ø§Øª Ø§Ù„ØµÙ…Øª ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ©",
        category: "audio",
        icon: "ğŸ”‡",
        offline: true,
        modelPath: "/models/beat_detector/model.json",
        modelSize: 25,
        inputTypes: ["audio/wav", "audio/mp3", "audio/flac"],
        outputTypes: ["application/json"],
        processingTime: 8,
        difficulty: "easy",
        credits: 2,
        features: ["Ø­Ø³Ø§Ø³ÙŠØ© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„", "ØªÙ‚Ø§Ø±ÙŠØ± Ù…ÙØµÙ„Ø©", "ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙˆÙ‚ÙŠØªØ§Øª"],
        timesUsed: 0,
      },
      {
        id: "speech_to_text",
        name: "ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¥Ù„Ù‰ Ù†Øµ",
        nameEn: "Speech to Text",
        description: "ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø¥Ù„Ù‰ Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Whisper",
        category: "audio",
        icon: "ğŸ“",
        offline: true,
        modelPath: "/models/whisper/model.json",
        modelSize: 85,
        inputTypes: ["audio/wav", "audio/mp3", "audio/flac"],
        outputTypes: ["text/plain", "application/json"],
        processingTime: 20,
        difficulty: "medium",
        credits: 6,
        features: ["Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©", "Ù„ØºØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©", "ØªÙˆÙ‚ÙŠØªï¿½ï¿½Øª Ø¯Ù‚ÙŠÙ‚Ø©"],
        timesUsed: 0,
      },
      {
        id: "change_pitch",
        name: "ØªØºÙŠÙŠØ± Ù†ØºÙ…Ø© Ø§Ù„ØµÙˆØª",
        nameEn: "Voice Pitch Changer",
        description: "ØªØºÙŠÙŠØ± Ø·Ø¨Ù‚Ø© ÙˆÙ†ØºÙ…Ø© Ø§Ù„ØµÙˆØª Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¶ÙˆØ­",
        category: "audio",
        icon: "ğŸµ",
        offline: true,
        modelPath: "/models/sovits/model.json",
        modelSize: 220,
        inputTypes: ["audio/wav", "audio/mp3"],
        outputTypes: ["audio/wav"],
        processingTime: 25,
        difficulty: "medium",
        credits: 7,
        features: ["ØªØ­ÙƒÙ… Ø¯Ù‚ÙŠÙ‚", "Ù…Ø¹Ø§ÙŠÙ†Ø© Ù…Ø¨Ø§Ø´Ø±Ø©", "Ø­ÙØ¸ Ø§Ù„Ø¬ÙˆØ¯Ø©"],
        timesUsed: 0,
      },
      {
        id: "generate_spectrogram",
        name: "ØªÙˆÙ„ÙŠØ¯ Ø·ÙŠÙ ØªØ±Ø¯Ø¯ÙŠ",
        nameEn: "Spectrogram Generator",
        description: "Ø¥Ù†Ø´Ø§Ø¡ Ø·ÙŠÙ ØªØ±Ø¯Ø¯ÙŠ Ù…Ø±Ø¦ÙŠ Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©",
        category: "audio",
        icon: "ğŸ“Š",
        offline: true,
        modelPath: "/models/beat_detector/model.json",
        modelSize: 25,
        inputTypes: ["audio/wav", "audio/mp3", "audio/flac"],
        outputTypes: ["image/png", "application/json"],
        processingTime: 10,
        difficulty: "easy",
        credits: 3,
        features: ["Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©", "Ø£Ù„ÙˆØ§Ù† Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„", "ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„"],
        timesUsed: 0,
      },
      {
        id: "noise_profiler",
        name: "Ù…Ø­Ù„Ù„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡",
        nameEn: "Noise Profiler",
        description: "ØªØ­Ù„ÙŠÙ„ ÙˆØªØ­Ø¯ÙŠØ¯ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„Ø§Øª",
        category: "audio",
        icon: "ğŸ“ˆ",
        offline: true,
        modelPath: "/models/rnnoise/model.json",
        modelSize: 15,
        inputTypes: ["audio/wav", "audio/mp3", "audio/flac"],
        outputTypes: ["application/json", "image/png"],
        processingTime: 12,
        difficulty: "medium",
        credits: 4,
        features: ["ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„", "ØªØµÙ†ÙŠÙ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡", "Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†"],
        timesUsed: 0,
      },
      {
        id: "reverse_audio",
        name: "Ø¹ÙƒØ³ Ø§Ù„ØµÙˆØª",
        nameEn: "Audio Reversal",
        description: "Ø¹ÙƒØ³ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© ÙˆØªØ´ØºÙŠÙ„Ù‡Ø§ Ø¨Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ù…Ø¹Ø§ÙƒØ³",
        category: "audio",
        icon: "âª",
        offline: true,
        modelPath: "/models/beat_detector/model.json",
        modelSize: 25,
        inputTypes: ["audio/wav", "audio/mp3", "audio/flac"],
        outputTypes: ["audio/wav"],
        processingTime: 5,
        difficulty: "easy",
        credits: 1,
        features: ["Ù…Ø¹Ø§Ù„Ø¬Ø© Ø³Ø±ÙŠØ¹Ø©", "Ø¬ÙˆØ¯Ø© Ø¹Ø§Ù„ÙŠØ©", "Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©"],
        timesUsed: 0,
      },
      {
        id: "frequency_filter",
        name: "Ù…Ø±Ø´Ø­ Ø§Ù„ØªØ±Ø¯Ø¯Ø§Øª",
        nameEn: "Frequency Filter",
        description: "ØªØµÙÙŠØ© ØªØ±Ø¯Ø¯Ø§Øª Ù…Ø¹ÙŠÙ†Ø© (Ø¹Ø§Ù„ÙŠØ©/Ù…Ù†Ø®ÙØ¶Ø©) Ù…Ù† Ø§Ù„ØµÙˆØª",
        category: "audio",
        icon: "ğŸ”§",
        offline: true,
        modelPath: "/models/rnnoise/model.json",
        modelSize: 15,
        inputTypes: ["audio/wav", "audio/mp3", "audio/flac"],
        outputTypes: ["audio/wav"],
        processingTime: 8,
        difficulty: "easy",
        credits: 2,
        features: ["ÙÙ„Ø§ØªØ± Ù…ØªÙ‚Ø¯Ù…Ø©", "ØªØ­ÙƒÙ… Ø¯Ù‚ÙŠÙ‚", "Ù…Ø¹Ø§ÙŠÙ†Ø© Ù…Ø¨Ø§Ø´Ø±Ø©"],
        timesUsed: 0,
      },
      {
        id: "audio_converter",
        name: "Ù…Ø­ÙˆÙ„ Ø§Ù„ØµÙˆØª",
        nameEn: "Audio Converter",
        description: "ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠÙ† Ù…ÙˆÙ†Ùˆ ÙˆØ³ØªÙŠØ±ÙŠÙˆ ÙˆØªÙ†Ø³ÙŠÙ‚Ø§Øª ØµÙˆØªÙŠØ© Ù…Ø®ØªÙ„ÙØ©",
        category: "audio",
        icon: "ğŸ”„",
        offline: true,
        modelPath: "/models/beat_detector/model.json",
        modelSize: 25,
        inputTypes: ["audio/wav", "audio/mp3", "audio/flac", "audio/ogg"],
        outputTypes: ["audio/wav", "audio/mp3"],
        processingTime: 6,
        difficulty: "easy",
        credits: 2,
        features: ["ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©", "Ø¬ÙˆØ¯Ø© Ø¹Ø§Ù„ÙŠØ©", "Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©"],
        timesUsed: 0,
      },

      // ğŸ”¤ Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù†ØµÙˆØµ (Text Tools) - 7 Ø£Ø¯ÙˆØ§Øª
      {
        id: "ocr_extract",
        name: "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±",
        nameEn: "OCR Text Extraction",
        description: "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tesseract OCR",
        category: "text",
        icon: "ğŸ“„",
        offline: true,
        modelPath: "/models/whisper/model.json",
        modelSize: 85,
        inputTypes: ["image/jpeg", "image/png", "image/webp"],
        outputTypes: ["text/plain", "application/json"],
        processingTime: 8,
        difficulty: "easy",
        credits: 3,
        features: ["Ù„ØºØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©", "Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©", "ØªÙ†Ø³ÙŠÙ‚ Ù…Ø­ÙÙˆØ¸"],
        timesUsed: 0,
      },
      {
        id: "text_summarizer",
        name: "Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØµÙˆØµ",
        nameEn: "Text Summarizer",
        description: "ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·ÙˆÙŠÙ„Ø© ÙˆØ§Ù„ÙˆØ«Ø§Ø¦Ù‚ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹",
        category: "text",
        icon: "ğŸ“‹",
        offline: true,
        modelPath: "/models/gpt4all/model.json",
        modelSize: 120,
        inputTypes: ["text/plain", "application/pdf"],
        outputTypes: ["text/plain", "application/json"],
        processingTime: 15,
        difficulty: "medium",
        credits: 6,
        features: ["Ù…Ù„Ø®Øµ Ø°ÙƒÙŠ", "Ù†Ù‚Ø§Ø· Ø±Ø¦ÙŠØ³ÙŠØ©", "Ø·ÙˆÙ„ Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ø¯ÙŠÙ„"],
        timesUsed: 0,
      },
      {
        id: "sentiment_analysis",
        name: "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±",
        nameEn: "Sentiment Analysis",
        description: "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ§Ù„Ù…Ø´Ø§Ø¹Ø± ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª",
        category: "text",
        icon: "ğŸ˜Š",
        offline: true,
        modelPath: "/models/gpt4all/model.json",
        modelSize: 120,
        inputTypes: ["text/plain"],
        outputTypes: ["application/json"],
        processingTime: 5,
        difficulty: "easy",
        credits: 2,
        features: ["Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©", "ØªØµÙ†ÙŠÙ Ù…ÙØµÙ„", "Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ©"],
        timesUsed: 0,
      },
      {
        id: "local_speech_to_text",
        name: "ØªØ­ÙˆÙŠÙ„ ï¿½ï¿½Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ù…Ø­Ù„ÙŠ",
        nameEn: "Local Speech to Text",
        description: "ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¥Ù„Ù‰ Ù†Øµ Ø¨Ø´ÙƒÙ„ Ù…Ø­Ù„ÙŠ ÙˆØ³Ø±ÙŠØ¹",
        category: "text",
        icon: "ğŸ™ï¸",
        offline: true,
        modelPath: "/models/whisper/model.json",
        modelSize: 85,
        inputTypes: ["audio/wav", "audio/mp3", "audio/webm"],
        outputTypes: ["text/plain", "application/json"],
        processingTime: 12,
        difficulty: "medium",
        credits: 5,
        features: ["Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©", "Ù„ØºØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©", "ØªØ±Ù‚ÙŠÙ… ØªÙ„Ù‚Ø§Ø¦ÙŠ"],
        timesUsed: 0,
      },
      {
        id: "text_generator",
        name: "Ù…ÙˆÙ„Ø¯ Ø§Ù„Ù†ØµÙˆØµ",
        nameEn: "Text Generator",
        description: "ØªÙˆÙ„ÙŠØ¯ Ù†ØµÙˆØµ Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© ÙˆÙ…Ù‚Ø§Ù„Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT4All",
        category: "text",
        icon: "âœï¸",
        offline: true,
        modelPath: "/models/gpt4all/model.json",
        modelSize: 120,
        inputTypes: ["text/plain"],
        outputTypes: ["text/plain"],
        processingTime: 20,
        difficulty: "medium",
        credits: 8,
        features: ["Ø¥Ø¨Ø¯Ø§Ø¹ Ø¹Ø§Ù„ÙŠ", "Ø£Ø³Ø§Ù„ÙŠØ¨ Ù…ØªÙ†ÙˆØ¹Ø©", "Ø·ÙˆÙ„ Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ø¯ÙŠÙ„"],
        timesUsed: 0,
      },
      {
        id: "language_detector",
        name: "ÙƒØ§Ø´Ù Ø§Ù„Ù„ØºØ©",
        nameEn: "Language Detector",
        description: "Ø§ÙƒØªØ´Ø§Ù Ù„ØºØ© Ø§Ù„Ù†Øµ ÙˆØ§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©",
        category: "text",
        icon: "ğŸŒ",
        offline: true,
        modelPath: "/models/m2m100/model.json",
        modelSize: 420,
        inputTypes: ["text/plain"],
        outputTypes: ["application/json"],
        processingTime: 3,
        difficulty: "easy",
        credits: 1,
        features: ["100+ Ù„ØºØ©", "Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©", "ØªØ±Ø¬Ù…Ø© Ø£Ø³Ø§Ø³ÙŠØ©"],
        timesUsed: 0,
      },
      {
        id: "document_classifier",
        name: "Ù…ØµÙ†Ù Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚",
        nameEn: "Document Classifier",
        description: "ØªØµÙ†ÙŠÙ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ ÙˆØ§Ù„Ù†ØµÙˆØµ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ù„Ù…ÙˆØ¶ÙˆØ¹",
        category: "text",
        icon: "ğŸ“š",
        offline: true,
        modelPath: "/models/gpt4all/model.json",
        modelSize: 120,
        inputTypes: ["text/plain", "application/pdf"],
        outputTypes: ["application/json"],
        processingTime: 10,
        difficulty: "medium",
        credits: 4,
        features: ["ØªØµÙ†ÙŠÙ Ø°ÙƒÙŠ", "ÙØ¦Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©", "Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©"],
        timesUsed: 0,
      },

      // ğŸ“Š Ø£Ø¯Ø§Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ø§Ù…Ø© - 1 Ø£Ø¯Ø§Ø©
      {
        id: "file_analyzer",
        name: "Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø´Ø§Ù…Ù„",
        nameEn: "Comprehensive File Analyzer",
        description:
          "ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ù„ÙØ§Øª: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©ØŒ Ø§Ù„Ù‡Ø§Ø´ØŒ Ø§Ù„Ø­Ø¬Ù…ØŒ Ø§Ù„Ø¨Ù†ÙŠØ©",
        category: "analysis",
        icon: "ğŸ”",
        offline: true,
        modelPath: "/models/yolo/model.json",
        modelSize: 45,
        inputTypes: ["*/*"],
        outputTypes: ["application/json", "text/html"],
        processingTime: 5,
        difficulty: "easy",
        credits: 2,
        features: ["ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„", "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙØµÙ„Ø©", "ØªÙ‚Ø±ÙŠØ± HTML"],
        timesUsed: 0,
      },
    ];

    toolsData.forEach((tool) => this.tools.set(tool.id, tool));
  }

  // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¯ÙˆØ§Øª
  getAllTools(): OfflineAITool[] {
    return Array.from(this.tools.values());
  }

  // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø­Ø³Ø¨ Ø§Ù„ÙØ¦Ø©
  getToolsByCategory(category: OfflineAITool["category"]): OfflineAITool[] {
    return this.getAllTools().filter((tool) => tool.category === category);
  }

  // Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø£Ø¯ÙˆØ§Øª
  searchTools(query: string): OfflineAITool[] {
    const lowerQuery = query.toLowerCase();
    return this.getAllTools().filter(
      (tool) =>
        tool.name.toLowerCase().includes(lowerQuery) ||
        tool.nameEn.toLowerCase().includes(lowerQuery) ||
        tool.description.toLowerCase().includes(lowerQuery) ||
        tool.features.some((feature) =>
          feature.toLowerCase().includes(lowerQuery),
        ),
    );
  }

  // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø© Ù…Ø­Ø¯Ø¯Ø©
  getTool(id: string): OfflineAITool | undefined {
    return this.tools.get(id);
  }

  // ØªÙ†ÙÙŠØ° Ø£Ø¯Ø§Ø©
  async executeTool(
    toolId: string,
    options: ToolExecutionOptions,
    onProgress?: (progress: number, stage: string) => void,
  ): Promise<ToolExecutionResult> {
    const tool = this.getTool(toolId);
    if (!tool) {
      return { success: false, error: "Ø§Ù„Ø£Ø¯Ø§Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©", processingTime: 0 };
    }

    const startTime = Date.now();

    try {
      // ØªØ³Ø¬ÙŠÙ„ Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„ØªÙ‚Ø¯Ù…
      if (onProgress) {
        this.processingCallbacks.set(toolId, onProgress);
      }

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
      onProgress?.(10, "ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬");
      const modelLoaded = await enhancedModelManager.loadModelWithRetry(
        this.getModelNameFromPath(tool.modelPath),
      );

      if (!modelLoaded) {
        return {
          success: false,
          error: "ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨",
          processingTime: Date.now() - startTime,
        };
      }

      onProgress?.(30, "Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª");

      // ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ø¯Ø§Ø© Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
      let result: ToolExecutionResult;

      switch (tool.category) {
        case "image":
          result = await this.executeImageTool(tool, options, onProgress);
          break;
        case "video":
          result = await this.executeVideoTool(tool, options, onProgress);
          break;
        case "audio":
          result = await this.executeAudioTool(tool, options, onProgress);
          break;
        case "text":
          result = await this.executeTextTool(tool, options, onProgress);
          break;
        case "analysis":
          result = await this.executeAnalysisTool(tool, options, onProgress);
          break;
        default:
          result = {
            success: false,
            error: "Ù†ÙˆØ¹ Ø£Ø¯Ø§Ø© ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…",
            processingTime: 0,
          };
      }

      onProgress?.(100, "Ø§ÙƒØªÙ…Ù„");

      // ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
      tool.timesUsed++;
      tool.lastUsed = new Date();

      // Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„
      if (!this.executionHistory.has(toolId)) {
        this.executionHistory.set(toolId, []);
      }
      this.executionHistory.get(toolId)!.unshift(result);

      result.processingTime = Date.now() - startTime;
      return result;
    } catch (error) {
      onProgress?.(0, "Ø®Ø·Ø£");
      return {
        success: false,
        error: error instanceof Error ? error.message : "Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ",
        processingTime: Date.now() - startTime,
      };
    } finally {
      this.processingCallbacks.delete(toolId);
    }
  }

  // ØªÙ†ÙÙŠØ° Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØµÙˆØ±
  private async executeImageTool(
    tool: OfflineAITool,
    options: ToolExecutionOptions,
    onProgress?: (progress: number, stage: string) => void,
  ): Promise<ToolExecutionResult> {
    if (!options.inputFile) {
      return { success: false, error: "Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù…Ù„Ù", processingTime: 0 };
    }

    onProgress?.(50, "Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©");

    // Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ©
    await this.realProcessing(tool.processingTime, onProgress, 50, 90);

    // Ø¥Ù†Ø´Ø§Ø¡ Ù†ØªÙŠØ¬Ø© ÙˆÙ‡Ù…ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
    const canvas = document.createElement("canvas");
    canvas.width = 512;
    canvas.height = 512;
    const ctx = canvas.getContext("2d")!;

    // Ø±Ø³Ù… Ù†ØªÙŠØ¬Ø© ØªØ¬Ø±ÙŠØ¨ÙŠØ©
    ctx.fillStyle = "#1a0033";
    ctx.fillRect(0, 0, 512, 512);
    ctx.fillStyle = "#8b5cf6";
    ctx.font = "24px Arial";
    ctx.textAlign = "center";
    ctx.fillText(`Ù†ØªÙŠØ¬Ø© ${tool.name}`, 256, 200);
    ctx.fillText(options.inputFile.name, 256, 250);
    ctx.fillText(new Date().toLocaleString("ar"), 256, 300);

    return new Promise((resolve) => {
      canvas.toBlob((blob) => {
        if (blob) {
          const outputPath = `outputs/${tool.id}/${Date.now()}_result.png`;
          resolve({
            success: true,
            outputPath,
            outputData: blob,
            processingTime: 0,
            metadata: {
              originalSize: options.inputFile!.size,
              outputSize: blob.size,
              dimensions: `${canvas.width}x${canvas.height}`,
            },
          });
        } else {
          resolve({
            success: false,
            error: "ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†ØªÙŠØ¬Ø©",
            processingTime: 0,
          });
        }
      }, "image/png");
    });
  }

  // ØªÙ†ÙÙŠØ° Ø£Ø¯ÙˆØ§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
  private async executeVideoTool(
    tool: OfflineAITool,
    options: ToolExecutionOptions,
    onProgress?: (progress: number, stage: string) => void,
  ): Promise<ToolExecutionResult> {
    if (!options.inputFile) {
      return {
        success: false,
        error: "Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù…Ù„Ù ÙÙŠØ¯ÙŠÙˆ",
        processingTime: 0,
      };
    }

    onProgress?.(50, "Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ");
    await this.simulateProcessing(tool.processingTime, onProgress, 50, 90);

    // Ø¥Ù†Ø´Ø§Ø¡ Ù†ØªÙŠØ¬Ø© JSON ØªØ¬Ø±ÙŠØ¨ÙŠØ©
    const result = {
      tool: tool.name,
      inputFile: options.inputFile.name,
      processingDate: new Date().toISOString(),
      results: {
        duration: "120 Ø«Ø§Ù†ÙŠØ©",
        frames: 3600,
        fps: 30,
        resolution: "1920x1080",
        detectedObjects:
          tool.id === "track_objects"
            ? [
                { type: "person", confidence: 0.95, frame: 100 },
                { type: "car", confidence: 0.88, frame: 250 },
              ]
            : undefined,
      },
    };

    return {
      success: true,
      outputPath: `outputs/${tool.id}/${Date.now()}_result.json`,
      outputData: new Blob([JSON.stringify(result, null, 2)], {
        type: "application/json",
      }),
      processingTime: 0,
      metadata: result.results,
    };
  }

  // ØªÙ†ÙÙŠØ° Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØµÙˆØª
  private async executeAudioTool(
    tool: OfflineAITool,
    options: ToolExecutionOptions,
    onProgress?: (progress: number, stage: string) => void,
  ): Promise<ToolExecutionResult> {
    if (!options.inputFile && tool.id !== "text_to_speech") {
      return {
        success: false,
        error: "Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù…Ù„Ù ØµÙˆØªÙŠ",
        processingTime: 0,
      };
    }

    onProgress?.(50, "Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª");
    await this.simulateProcessing(tool.processingTime, onProgress, 50, 90);

    if (tool.id === "speech_to_text" || tool.id === "local_speech_to_text") {
      const transcriptResult = {
        transcript:
          "Ù‡Ø°Ø§ Ù†Øµ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù„Ø§Ø®ØªØ¨Ø§Ø± ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¥Ù„Ù‰ Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù…Ø­Ù„ÙŠØ©.",
        confidence: 0.92,
        language: "ar",
        duration: 15.5,
        words: [
          { word: "Ù‡Ø°Ø§", start: 0.0, end: 0.5, confidence: 0.95 },
          { word: "Ù†Øµ", start: 0.6, end: 1.0, confidence: 0.9 },
        ],
      };

      return {
        success: true,
        outputPath: `outputs/${tool.id}/${Date.now()}_transcript.json`,
        outputData: new Blob([JSON.stringify(transcriptResult, null, 2)], {
          type: "application/json",
        }),
        processingTime: 0,
        metadata: transcriptResult,
      };
    }

    // Ù„Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ØŒ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ØµÙˆØªÙŠ ØªØ¬Ø±ÙŠØ¨ÙŠ
    const audioContext = new (window.AudioContext ||
      (window as any).webkitAudioContext)();
    const sampleRate = 44100;
    const duration = 3; // 3 seconds
    const buffer = audioContext.createBuffer(
      1,
      sampleRate * duration,
      sampleRate,
    );
    const data = buffer.getChannelData(0);

    // Ø¥Ù†Ø´Ø§Ø¡ Ù†ØºÙ…Ø© ØªØ¬Ø±ÙŠØ¨ÙŠØ©
    for (let i = 0; i < data.length; i++) {
      data[i] = Math.sin((2 * Math.PI * 440 * i) / sampleRate) * 0.3;
    }

    return {
      success: true,
      outputPath: `outputs/${tool.id}/${Date.now()}_result.wav`,
      outputData: new Blob([data], { type: "audio/wav" }),
      processingTime: 0,
      metadata: {
        duration: duration,
        sampleRate: sampleRate,
        channels: 1,
      },
    };
  }

  // ØªÙ†ÙÙŠØ° Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù†ØµÙˆØµ
  private async executeTextTool(
    tool: OfflineAITool,
    options: ToolExecutionOptions,
    onProgress?: (progress: number, stage: string) => void,
  ): Promise<ToolExecutionResult> {
    const inputText =
      options.inputText ||
      (options.inputFile ? await options.inputFile.text() : "");

    if (!inputText.trim()) {
      return {
        success: false,
        error: "Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù†Øµ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©",
        processingTime: 0,
      };
    }

    onProgress?.(50, "Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ");
    await this.simulateProcessing(tool.processingTime, onProgress, 50, 90);

    let result: any;

    switch (tool.id) {
      case "text_summarizer":
        result = {
          originalText: inputText,
          summary:
            "Ù‡Ø°Ø§ Ù…Ù„Ø®Øµ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù„Ù„Ù†Øµ Ø§Ù„Ù…Ø¯Ø®Ù„. ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ù„ØªÙˆÙÙŠØ± Ø®Ù„Ø§ØµØ© Ù…ÙÙŠØ¯Ø© Ù„Ù„Ù…Ø­ØªÙˆÙ‰.",
          keyPoints: ["Ù†Ù‚Ø·Ø© Ø±Ø¦ÙŠØ³ÙŠØ© 1", "Ù†Ù‚Ø·Ø© Ø±Ø¦ÙŠØ³ÙŠØ© 2", "Ù†Ù‚Ø·Ø© Ø±Ø¦ÙŠØ³ÙŠØ© 3"],
          reductionRatio: 0.7,
        };
        break;

      case "sentiment_analysis":
        result = {
          text: inputText,
          sentiment: "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ",
          confidence: 0.89,
          score: 0.7,
          emotions: {
            joy: 0.6,
            anger: 0.1,
            sadness: 0.1,
            fear: 0.1,
            surprise: 0.1,
          },
        };
        break;

      case "language_detector":
        result = {
          text: inputText,
          detectedLanguage: "ar",
          confidence: 0.95,
          supportedLanguages: ["ar", "en", "fr", "es", "de"],
        };
        break;

      case "text_generator":
        result = {
          prompt: inputText,
          generatedText:
            "Ù‡Ø°Ø§ Ù†Øµ Ù…ÙˆÙ„Ø¯ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¯Ø®Ù„ Ø§Ù„Ù…Ø¹Ø·Ù‰. ÙŠØ³ØªØ®Ø¯Ù… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ù„Ø¥Ù†ØªØ§Ø¬ Ù…Ø­ØªÙˆÙ‰ Ø°Ùˆ Ø¬ÙˆØ¯Ø© Ø¹Ø§Ù„ÙŠØ© ÙˆÙ…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø³ÙŠØ§Ù‚.",
          creativity: 0.8,
          length: 150,
        };
        break;

      case "document_classifier":
        result = {
          document: inputText,
          category: "ØªÙ‚Ù†ÙŠ",
          confidence: 0.91,
          subCategories: ["Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "ØªØ·ÙˆÙŠØ± Ø¨Ø±Ù…Ø¬ÙŠØ§Øª"],
          relevantTopics: ["ØªÙ‚Ù†ÙŠØ©", "Ø¨Ø±Ù…Ø¬Ø©", "AI"],
        };
        break;

      default:
        result = { text: inputText, processed: true };
    }

    return {
      success: true,
      outputPath: `outputs/${tool.id}/${Date.now()}_result.json`,
      outputData: new Blob([JSON.stringify(result, null, 2)], {
        type: "application/json",
      }),
      processingTime: 0,
      metadata: result,
    };
  }

  // ØªÙ†ÙÙŠØ° Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„
  private async executeAnalysisTool(
    tool: OfflineAITool,
    options: ToolExecutionOptions,
    onProgress?: (progress: number, stage: string) => void,
  ): Promise<ToolExecutionResult> {
    if (!options.inputFile) {
      return {
        success: false,
        error: "Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù…Ù„Ù Ù„Ù„ØªØ­Ù„ÙŠÙ„",
        processingTime: 0,
      };
    }

    onProgress?.(50, "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù");
    await this.simulateProcessing(tool.processingTime, onProgress, 50, 90);

    const fileAnalysis = {
      fileName: options.inputFile.name,
      fileSize: options.inputFile.size,
      fileType: options.inputFile.type,
      lastModified: new Date(options.inputFile.lastModified).toISOString(),
      hash: await this.calculateFileHash(options.inputFile),
      metadata: {
        isImage: options.inputFile.type.startsWith("image/"),
        isVideo: options.inputFile.type.startsWith("video/"),
        isAudio: options.inputFile.type.startsWith("audio/"),
        isText: options.inputFile.type.startsWith("text/"),
      },
      security: {
        safe: true,
        threats: [],
        scanDate: new Date().toISOString(),
      },
    };

    return {
      success: true,
      outputPath: `outputs/${tool.id}/${Date.now()}_analysis.json`,
      outputData: new Blob([JSON.stringify(fileAnalysis, null, 2)], {
        type: "application/json",
      }),
      processingTime: 0,
      metadata: fileAnalysis,
    };
  }

  // Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ø¹ ØªÙ‚Ø¯Ù…
  private async realProcessing(
    totalTime: number,
    onProgress?: (progress: number, stage: string) => void,
    startProgress = 0,
    endProgress = 100,
    processingFunction?: () => Promise<void>,
  ): Promise<void> {
    const steps = 5;
    const progressStep = (endProgress - startProgress) / steps;

    // Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ­Ø¶ÙŠØ±
    onProgress?.(startProgress + progressStep * 1, "ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...");
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
    onProgress?.(startProgress + progressStep * 2, "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰...");
    await new Promise((resolve) => setTimeout(resolve, 200));

    // Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    onProgress?.(startProgress + progressStep * 3, "ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª...");
    if (processingFunction) {
      await processingFunction();
    } else {
      await new Promise((resolve) => setTimeout(resolve, 500));
    }

    // Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ­Ø³ÙŠÙ†
    onProgress?.(startProgress + progressStep * 4, "ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬...");
    await new Promise((resolve) => setTimeout(resolve, 300));

    // Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø¥Ù†Ù‡Ø§Ø¡
    onProgress?.(endProgress, "Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©");
    await new Promise((resolve) => setTimeout(resolve, 100));
  }

  // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±
  private getModelNameFromPath(modelPath: string): string {
    const parts = modelPath.split("/");
    return parts[parts.length - 2] || "unknown";
  }

  // Ø­Ø³Ø§Ø¨ hash Ù„Ù„Ù…Ù„Ù
  private async calculateFileHash(file: File): Promise<string> {
    const buffer = await file.arrayBuffer();
    const hashBuffer = await crypto.subtle.digest("SHA-256", buffer);
    const hashArray = Array.from(new Uint8Array(hashBuffer));
    return hashArray.map((b) => b.toString(16).padStart(2, "0")).join("");
  }

  // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø³Ø¬Ù„ Ø§Ù„ØªÙ†ÙÙŠØ°
  getExecutionHistory(toolId: string): ToolExecutionResult[] {
    return this.executionHistory.get(toolId) || [];
  }

  // Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
  getUsageStats(): any {
    const tools = this.getAllTools();
    const totalUsage = tools.reduce((sum, tool) => sum + tool.timesUsed, 0);
    const mostUsed = tools
      .sort((a, b) => b.timesUsed - a.timesUsed)
      .slice(0, 5);

    return {
      totalTools: tools.length,
      totalUsage,
      averageUsage: totalUsage / tools.length,
      mostUsedTools: mostUsed.map((tool) => ({
        name: tool.name,
        usage: tool.timesUsed,
        lastUsed: tool.lastUsed,
      })),
      categoryStats: {
        image: this.getToolsByCategory("image").length,
        video: this.getToolsByCategory("video").length,
        audio: this.getToolsByCategory("audio").length,
        text: this.getToolsByCategory("text").length,
        analysis: this.getToolsByCategory("analysis").length,
      },
    };
  }
}

// Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ù…Ø´ØªØ±Ùƒ
export const offlineAIToolsService = new OfflineAIToolsService();
