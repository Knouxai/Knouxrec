import { useState, useRef, useCallback, useEffect } from "react";
import RecordRTC, { StereoAudioRecorder, MediaStreamRecorder } from "recordrtc";
import {
  screenshotService,
  ScreenshotOptions,
  ScreenshotResult,
} from "../services/screenshotService";

export interface RecorderState {
  isRecording: boolean;
  isPaused: boolean;
  recordingTime: number;
  recordingBlob: Blob | null;
  error: string | null;
  isInitialized: boolean;
  devices: MediaDeviceInfo[];
  currentDevice: string | null;
  recordingQuality: "low" | "medium" | "high" | "ultra";
  includeAudio: boolean;
  includeMicrophone: boolean;
  frameRate: number;
  bitRate: number;
}

export interface RecorderActions {
  startRecording: () => Promise<void>;
  stopRecording: () => Promise<void>;
  pauseRecording: () => void;
  resumeRecording: () => void;
  initialize: () => Promise<void>;
  setRecordingQuality: (quality: RecorderState["recordingQuality"]) => void;
  setIncludeAudio: (include: boolean) => void;
  setIncludeMicrophone: (include: boolean) => void;
  setDevice: (deviceId: string) => void;
  setFrameRate: (fps: number) => void;
  setBitRate: (bitrate: number) => void;
  downloadRecording: () => void;
  clearRecording: () => void;
  takeScreenshot: (options?: ScreenshotOptions) => Promise<ScreenshotResult>;
  startWebcamRecording: () => Promise<void>;
  recordSpecificWindow: () => Promise<void>;
  recordSelectedArea: (
    x: number,
    y: number,
    width: number,
    height: number,
  ) => Promise<void>;
}

export interface UseRecorderReturn {
  state: RecorderState;
  actions: RecorderActions;
}

const QUALITY_SETTINGS = {
  low: { width: 1280, height: 720, bitRate: 2500000, frameRate: 15 },
  medium: { width: 1920, height: 1080, bitRate: 5000000, frameRate: 30 },
  high: { width: 2560, height: 1440, bitRate: 8000000, frameRate: 30 },
  ultra: { width: 3840, height: 2160, bitRate: 15000000, frameRate: 60 },
};

export function useRecorder(): UseRecorderReturn {
  const [state, setState] = useState<RecorderState>({
    isRecording: false,
    isPaused: false,
    recordingTime: 0,
    recordingBlob: null,
    error: null,
    isInitialized: false,
    devices: [],
    currentDevice: null,
    recordingQuality: "high",
    includeAudio: true,
    includeMicrophone: false,
    frameRate: 30,
    bitRate: 8000000,
  });

  const recorderRef = useRef<RecordRTC | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const startTimeRef = useRef<number>(0);
  const pausedTimeRef = useRef<number>(0);
  const canvasRef = useRef<HTMLCanvasElement | null>(null);

  // ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆÙ‚Øª
  const updateTimer = useCallback(() => {
    const now = Date.now();
    const elapsed = Math.floor(
      (now - startTimeRef.current - pausedTimeRef.current) / 1000,
    );
    setState((prev) => ({ ...prev, recordingTime: elapsed }));
  }, []);

  // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
  const initialize = useCallback(async () => {
    try {
      setState((prev) => ({ ...prev, error: null }));

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¯Ø¹Ù… Ø§Ù„Ù…ØªØµÙØ­
      if (!navigator.mediaDevices || !navigator.mediaDevices.getDisplayMedia) {
        throw new Error("Ø§Ù„Ù…ØªØµÙØ­ Ù„Ø§ ÙŠØ¯Ø¹Ù… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø´Ø§Ø´Ø©");
      }

      // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©
      const devices = await navigator.mediaDevices.enumerateDevices();
      const videoDevices = devices.filter(
        (device) => device.kind === "videoinput",
      );

      setState((prev) => ({
        ...prev,
        devices: videoDevices,
        currentDevice: videoDevices[0]?.deviceId || null,
        isInitialized: true,
      }));
    } catch (error) {
      setState((prev) => ({
        ...prev,
        error: error instanceof Error ? error.message : "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ‡ÙŠØ¦Ø©",
        isInitialized: false,
      }));
    }
  }, []);

  // Ø¥Ù†Ø´Ø§Ø¡ ØªØ¯ÙÙ‚ Ø§Ù„ÙˆØ³Ø§Ø¦Ø·
  const createMediaStream = useCallback(
    async (type: "screen" | "webcam" | "window" = "screen") => {
      const qualitySettings = QUALITY_SETTINGS[state.recordingQuality];

      let videoStream: MediaStream;

      if (type === "screen") {
        // ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø´Ø§Ø´Ø©
        videoStream = await navigator.mediaDevices.getDisplayMedia({
          video: {
            width: qualitySettings.width,
            height: qualitySettings.height,
            frameRate: state.frameRate,
            cursor: "always",
          },
          audio: state.includeAudio,
        });
      } else if (type === "webcam") {
        // ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
        videoStream = await navigator.mediaDevices.getUserMedia({
          video: {
            deviceId: state.currentDevice
              ? { exact: state.currentDevice }
              : undefined,
            width: qualitySettings.width,
            height: qualitySettings.height,
            frameRate: state.frameRate,
          },
          audio: state.includeMicrophone,
        });
      } else {
        // ØªØ³Ø¬ÙŠÙ„ Ù†Ø§ÙØ°Ø© Ù…Ø­Ø¯Ø¯Ø©
        videoStream = await navigator.mediaDevices.getDisplayMedia({
          video: {
            width: qualitySettings.width,
            height: qualitySettings.height,
            frameRate: state.frameRate,
            cursor: "always",
          },
          audio: state.includeAudio,
        });
      }

      // Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø·Ù„ÙˆØ¨Ø§Ù‹
      if (state.includeMicrophone && type === "screen") {
        try {
          const micStream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          });
          const audioContext = new AudioContext();
          const dest = audioContext.createMediaStreamDestination();

          // Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„Ø´Ø§Ø´Ø© ÙˆØ§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†
          const videoAudioSource =
            audioContext.createMediaStreamSource(videoStream);
          const micAudioSource =
            audioContext.createMediaStreamSource(micStream);

          videoAudioSource.connect(dest);
          micAudioSource.connect(dest);

          // Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØªÙŠ
          const audioTrack = dest.stream.getAudioTracks()[0];
          videoStream.removeTrack(videoStream.getAudioTracks()[0]);
          videoStream.addTrack(audioTrack);
        } catch (micError) {
          console.warn("ØªØ¹Ø°Ø± Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†:", micError);
        }
      }

      return videoStream;
    },
    [
      state.recordingQuality,
      state.includeAudio,
      state.includeMicrophone,
      state.currentDevice,
      state.frameRate,
    ],
  );

  // Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
  const startRecording = useCallback(async () => {
    try {
      setState((prev) => ({ ...prev, error: null }));

      const stream = await createMediaStream("screen");
      streamRef.current = stream;

      // Ø¥Ø¹Ø¯Ø§Ø¯ RecordRTC
      const options = {
        type: "video",
        mimeType: "video/webm;codecs=vp9",
        bitsPerSecond: state.bitRate,
        videoBitsPerSecond: state.bitRate,
        audioBitsPerSecond: 128000,
        frameInterval: 1000 / state.frameRate,
        quality: 10,
        canvas: {
          width: QUALITY_SETTINGS[state.recordingQuality].width,
          height: QUALITY_SETTINGS[state.recordingQuality].height,
        },
      };

      recorderRef.current = new RecordRTC(stream, options);
      recorderRef.current.startRecording();

      // Ø¨Ø¯Ø¡ Ø§Ù„Ø¹Ø¯Ø§Ø¯
      startTimeRef.current = Date.now();
      pausedTimeRef.current = 0;
      timerRef.current = setInterval(updateTimer, 1000);

      setState((prev) => ({
        ...prev,
        isRecording: true,
        isPaused: false,
        recordingTime: 0,
        recordingBlob: null,
      }));

      // Ù…Ø±Ø§Ù‚Ø¨Ø© Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
      stream.getVideoTracks()[0].addEventListener("ended", () => {
        stopRecording();
      });
    } catch (error) {
      setState((prev) => ({
        ...prev,
        error: error instanceof Error ? error.message : "Ø®Ø·Ø£ ÙÙŠ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„",
      }));
    }
  }, [
    createMediaStream,
    state.bitRate,
    state.frameRate,
    state.recordingQuality,
    updateTimer,
  ]);

  // Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„
  const stopRecording = useCallback(async () => {
    return new Promise<void>((resolve) => {
      if (!recorderRef.current || !state.isRecording) {
        resolve();
        return;
      }

      recorderRef.current.stopRecording(() => {
        const blob = recorderRef.current!.getBlob();

        // Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ¯ÙÙ‚
        if (streamRef.current) {
          streamRef.current.getTracks().forEach((track) => track.stop());
          streamRef.current = null;
        }

        // Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ø¯Ø§Ø¯
        if (timerRef.current) {
          clearInterval(timerRef.current);
          timerRef.current = null;
        }

        setState((prev) => ({
          ...prev,
          isRecording: false,
          isPaused: false,
          recordingBlob: blob,
        }));

        resolve();
      });
    });
  }, [state.isRecording]);

  // Ø¥ÙŠÙ‚Ø§Ù Ù…Ø¤Ù‚Øª
  const pauseRecording = useCallback(() => {
    if (!recorderRef.current || !state.isRecording || state.isPaused) return;

    recorderRef.current.pauseRecording();
    pausedTimeRef.current += Date.now() - startTimeRef.current;

    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }

    setState((prev) => ({ ...prev, isPaused: true }));
  }, [state.isRecording, state.isPaused]);

  // Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
  const resumeRecording = useCallback(() => {
    if (!recorderRef.current || !state.isRecording || !state.isPaused) return;

    recorderRef.current.resumeRecording();
    startTimeRef.current = Date.now();
    timerRef.current = setInterval(updateTimer, 1000);

    setState((prev) => ({ ...prev, isPaused: false }));
  }, [state.isRecording, state.isPaused, updateTimer]);

  // ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
  const downloadRecording = useCallback(() => {
    if (!state.recordingBlob) return;

    const url = URL.createObjectURL(state.recordingBlob);
    const a = document.createElement("a");
    a.href = url;
    a.download = `recording-${new Date().toISOString().slice(0, 19).replace(/[:.]/g, "-")}.webm`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
  }, [state.recordingBlob]);

  // Ù…Ø³Ø­ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
  const clearRecording = useCallback(() => {
    setState((prev) => ({
      ...prev,
      recordingBlob: null,
      recordingTime: 0,
      error: null,
    }));
  }, []);

  // Ø£Ø®Ø° Ù„Ù‚Ø·Ø© Ø´Ø§Ø´Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
  const takeScreenshot = useCallback(
    async (options?: ScreenshotOptions): Promise<ScreenshotResult> => {
      console.log("ðŸ“¸ Taking advanced screenshot...");

      try {
        // Ø¥Ø¹Ø¯Ø§Ø¯ Ø®ÙŠØ§Ø±Ø§Øª Screenshot Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        const screenshotOptions: ScreenshotOptions = {
          format: "png",
          quality: 0.95,
          captureMode: "screen",
          timestamp: true,
          watermark: true,
          ...options,
        };

        // Ø§Ù„ØªÙ‚Ø§Ø· Ù„Ù‚Ø·Ø© Ø§Ù„Ø´Ø§Ø´Ø©
        const result =
          await screenshotService.captureScreenshot(screenshotOptions);

        if (result.success) {
          console.log("âœ… Screenshot captured successfully:", result.filename);

          // ØªØ­Ù…ÙŠÙ„ Ù„Ù‚Ø·Ø© Ø§Ù„Ø´Ø§Ø´Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
          const downloaded = await screenshotService.downloadScreenshot(result);

          if (downloaded) {
            console.log("ðŸ“¥ Screenshot downloaded successfully");

            // Ù…Ø­Ø§ÙˆÙ„Ø© Ù†Ø³Ø® Ù„Ù‚Ø·Ø© Ø§Ù„Ø´Ø§Ø´Ø© Ù„Ù„Ø­Ø§ÙØ¸Ø© Ø£ÙŠØ¶Ø§Ù‹
            try {
              await screenshotService.copyToClipboard(result);
              console.log("ðŸ“‹ Screenshot copied to clipboard");
            } catch (error) {
              console.warn("Failed to copy to clipboard:", error);
            }
          } else {
            console.error("âŒ Failed to download screenshot");
          }

          return result;
        } else {
          console.error("âŒ Screenshot capture failed:", result.error);
          return result;
        }
      } catch (error) {
        console.error("Screenshot error:", error);
        return {
          success: false,
          error:
            error instanceof Error
              ? error.message
              : "ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªÙ‚Ø§Ø· Ù„Ù‚Ø·Ø© Ø§Ù„Ø´Ø§Ø´Ø©",
        };
      }
    },
    [],
  );

  // ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
  const startWebcamRecording = useCallback(async () => {
    try {
      const stream = await createMediaStream("webcam");
      streamRef.current = stream;

      const options = {
        type: "video",
        mimeType: "video/webm;codecs=vp9",
        bitsPerSecond: state.bitRate,
      };

      recorderRef.current = new RecordRTC(stream, options);
      recorderRef.current.startRecording();

      startTimeRef.current = Date.now();
      pausedTimeRef.current = 0;
      timerRef.current = setInterval(updateTimer, 1000);

      setState((prev) => ({
        ...prev,
        isRecording: true,
        isPaused: false,
        recordingTime: 0,
        recordingBlob: null,
      }));
    } catch (error) {
      setState((prev) => ({
        ...prev,
        error: error instanceof Error ? error.message : "Ø®Ø·Ø£ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§",
      }));
    }
  }, [createMediaStream, state.bitRate, updateTimer]);

  // ØªØ³Ø¬ÙŠÙ„ Ù†Ø§ÙØ°Ø© Ù…Ø­Ø¯Ø¯Ø©
  const recordSpecificWindow = useCallback(async () => {
    try {
      const stream = await createMediaStream("window");
      streamRef.current = stream;

      const options = {
        type: "video",
        mimeType: "video/webm;codecs=vp9",
        bitsPerSecond: state.bitRate,
      };

      recorderRef.current = new RecordRTC(stream, options);
      recorderRef.current.startRecording();

      startTimeRef.current = Date.now();
      pausedTimeRef.current = 0;
      timerRef.current = setInterval(updateTimer, 1000);

      setState((prev) => ({
        ...prev,
        isRecording: true,
        isPaused: false,
        recordingTime: 0,
        recordingBlob: null,
      }));
    } catch (error) {
      setState((prev) => ({
        ...prev,
        error: error instanceof Error ? error.message : "Ø®Ø·Ø£ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†Ø§ÙØ°Ø©",
      }));
    }
  }, [createMediaStream, state.bitRate, updateTimer]);

  // ØªØ³Ø¬ÙŠÙ„ Ù…Ù†Ø·Ù‚Ø© Ù…Ø­Ø¯Ø¯Ø©
  const recordSelectedArea = useCallback(
    async (x: number, y: number, width: number, height: number) => {
      try {
        // Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙŠØ²Ø© ØªØªØ·Ù„Ø¨ Ù…ÙƒØªØ¨Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ø£Ùˆ ØªØ·Ø¨ÙŠÙ‚ desktop
        console.log("ØªØ³Ø¬ÙŠÙ„ Ù…Ù†Ø·Ù‚Ø© Ù…Ø­Ø¯Ø¯Ø©:", { x, y, width, height });
        // TODO: ØªØ·Ø¨ÙŠÙ‚ ØªØ³Ø¬ÙŠÙ„ Ù…Ù†Ø·Ù‚Ø© Ù…Ø­Ø¯Ø¯Ø©
      } catch (error) {
        setState((prev) => ({
          ...prev,
          error:
            error instanceof Error
              ? error.message
              : "Ø®Ø·Ø£ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©",
        }));
      }
    },
    [],
  );

  // Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¬ÙˆØ¯Ø©
  const setRecordingQuality = useCallback(
    (quality: RecorderState["recordingQuality"]) => {
      setState((prev) => ({ ...prev, recordingQuality: quality }));
    },
    [],
  );

  const setIncludeAudio = useCallback((include: boolean) => {
    setState((prev) => ({ ...prev, includeAudio: include }));
  }, []);

  const setIncludeMicrophone = useCallback((include: boolean) => {
    setState((prev) => ({ ...prev, includeMicrophone: include }));
  }, []);

  const setDevice = useCallback((deviceId: string) => {
    setState((prev) => ({ ...prev, currentDevice: deviceId }));
  }, []);

  const setFrameRate = useCallback((fps: number) => {
    setState((prev) => ({ ...prev, frameRate: fps }));
  }, []);

  const setBitRate = useCallback((bitrate: number) => {
    setState((prev) => ({ ...prev, bitRate: bitrate }));
  }, []);

  // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø¹Ù†Ø¯ Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù…ÙƒÙˆÙ†
  useEffect(() => {
    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
      }
      // ØªÙ†Ø¸ÙŠÙ Ø®Ø¯Ù…Ø© Screenshot
      screenshotService.cleanup();
    };
  }, []);

  // ØªÙ‡ÙŠØ¦Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
  useEffect(() => {
    initialize();
  }, [initialize]);

  return {
    state,
    actions: {
      startRecording,
      stopRecording,
      pauseRecording,
      resumeRecording,
      initialize,
      setRecordingQuality,
      setIncludeAudio,
      setIncludeMicrophone,
      setDevice,
      setFrameRate,
      setBitRate,
      downloadRecording,
      clearRecording,
      takeScreenshot,
      startWebcamRecording,
      recordSpecificWindow,
      recordSelectedArea,
    },
  };
}
